{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Text Cleaning and Manipulation\n",
                "\n",
                "Prepare text data for analysis.\n",
                "\n",
                "## Common Tasks\n",
                "- **Normalization:** Lowercasing, removing whitespace.\n",
                "- **Removal:** Stopwords, punctuation, special chars.\n",
                "- **Extraction:** Dates, emails, phone numbers (Regex).\n",
                "- **Encoding:** Making text ready for ML.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import re\n",
                "\n",
                "# Create messy text data\n",
                "df = pd.DataFrame({\n",
                "    'Feedback': [\n",
                "        '  Great Product!  ',\n",
                "        'Loving it, 5 stars.',\n",
                "        'Not worth $50...',\n",
                "        'delivery was LATE!!!',\n",
                "        np.nan\n",
                "    ],\n",
                "    'Contact': [\n",
                "        'john@email.com',\n",
                "        'support@company.org',\n",
                "        '123-456-7890',\n",
                "        'No email',\n",
                "        'jane.doe@gmail.com'\n",
                "    ]\n",
                "})\n",
                "\n",
                "print(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Basic Normalization\n",
                "Lowercase and whitespace removal."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Always fill NaN first\n",
                "df['Feedback'] = df['Feedback'].fillna('')\n",
                "\n",
                "# Lowercase + Strip whitespace\n",
                "df['Cleaned'] = df['Feedback'].str.lower().str.strip()\n",
                "\n",
                "print(df[['Feedback', 'Cleaned']])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Removing Punctuation\n",
                "Using Regular Expressions (Regex)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove everything that is NOT a word char or space\n",
                "df['Cleaned'] = df['Cleaned'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
                "print(df['Cleaned'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Extracting Information (Regex)\n",
                "Find emails or patterns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Regex for email\n",
                "email_pattern = r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'\n",
                "\n",
                "df['Email_Extracted'] = df['Contact'].str.extract(email_pattern)\n",
                "print(df[['Contact', 'Email_Extracted']])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Engineering from Text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Character count\n",
                "df['Length'] = df['Cleaned'].str.len()\n",
                "\n",
                "# Word count\n",
                "df['Word_Count'] = df['Cleaned'].str.split().str.len()\n",
                "\n",
                "# Identify simple sentiment (keyword based)\n",
                "positive_words = ['great', 'loving', 'good']\n",
                "df['Is_Positive'] = df['Cleaned'].apply(\n",
                "    lambda x: any(word in x for word in positive_words)\n",
                ")\n",
                "\n",
                "print(df[['Cleaned', 'Length', 'Word_Count', 'Is_Positive']])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Fuzzy Matching (Advanced)\n",
                "Fixing typos (e.g., 'Aplle' -> 'Apple')."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Requires: pip install fuzzywuzzy python-Levenshtein\n",
                "# from fuzzywuzzy import process\n",
                "\n",
                "# choices = ['Apple', 'Banana', 'Orange']\n",
                "# process.extractOne('Aplle', choices)\n",
                "# Output: ('Apple', 100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Practice Exercise\n",
                "Clean the Name column in Titanic to extract Titles (Mr, Mrs, Miss)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load titanic\n",
                "# Extract 'Mr.', 'Mrs.', etc. using Regex\n",
                "# Check counts of each title\n",
                "# Your code here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Key Takeaways\n",
                "\n",
                "✅ **Normalization** - Critical first step.\n",
                "✅ **Regex** - Learn basics (`^`, `$`, `\\d`, `\\w`, `+`, `*`).\n",
                "✅ **Encoding** - Converting text to numbers is needed for ML.\n",
                "\n",
                "**Next:** [Data Cleaning Project](README.md) →"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}