{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# NumPy Statistics and Aggregations\n",
                "\n",
                "## üìö Learning Objectives\n",
                "- Calculate descriptive statistics\n",
                "- Understand axis-based operations\n",
                "- Work with percentiles and quantiles\n",
                "- Compute correlations and covariance\n",
                "- Apply statistical functions to real datasets\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Descriptive Statistics\n",
                "\n",
                "Basic statistical measures to understand data distribution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create sample data\n",
                "data = np.array([23, 45, 67, 12, 89, 34, 56, 78, 90, 45, 23, 67, 89, 12, 34])\n",
                "\n",
                "print(\"Data:\", data)\n",
                "print(\"\\n--- Measures of Central Tendency ---\")\n",
                "print(f\"Mean: {np.mean(data):.2f}\")\n",
                "print(f\"Median: {np.median(data):.2f}\")\n",
                "print(f\"Mode (most frequent): {np.bincount(data).argmax()}\")\n",
                "\n",
                "print(\"\\n--- Measures of Spread ---\")\n",
                "print(f\"Standard Deviation: {np.std(data):.2f}\")\n",
                "print(f\"Variance: {np.var(data):.2f}\")\n",
                "print(f\"Min: {np.min(data)}\")\n",
                "print(f\"Max: {np.max(data)}\")\n",
                "print(f\"Range (ptp): {np.ptp(data)}\")\n",
                "\n",
                "print(\"\\n--- Other Statistics ---\")\n",
                "print(f\"Sum: {np.sum(data)}\")\n",
                "print(f\"Product: {np.prod(data[:5])}\")  # First 5 elements (product gets large!)\n",
                "print(f\"Count: {len(data)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Percentiles and Quantiles\n",
                "\n",
                "Understand data distribution through percentiles."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate sample data\n",
                "data = np.random.randint(0, 100, size=100)\n",
                "\n",
                "print(\"Data sample:\", data[:20])\n",
                "print(\"\\n--- Percentiles ---\")\n",
                "print(f\"25th percentile (Q1): {np.percentile(data, 25):.2f}\")\n",
                "print(f\"50th percentile (Median/Q2): {np.percentile(data, 50):.2f}\")\n",
                "print(f\"75th percentile (Q3): {np.percentile(data, 75):.2f}\")\n",
                "print(f\"90th percentile: {np.percentile(data, 90):.2f}\")\n",
                "print(f\"95th percentile: {np.percentile(data, 95):.2f}\")\n",
                "\n",
                "# Interquartile Range (IQR)\n",
                "q1 = np.percentile(data, 25)\n",
                "q3 = np.percentile(data, 75)\n",
                "iqr = q3 - q1\n",
                "print(f\"\\nInterquartile Range (IQR): {iqr:.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quantiles (alternative to percentiles)\n",
                "data = np.random.normal(100, 15, 1000)  # Normal distribution\n",
                "\n",
                "print(\"--- Quantiles ---\")\n",
                "quantiles = np.quantile(data, [0.25, 0.5, 0.75])\n",
                "print(f\"Quartiles: {quantiles}\")\n",
                "\n",
                "# Deciles (10 equal parts)\n",
                "deciles = np.quantile(data, np.arange(0.1, 1.0, 0.1))\n",
                "print(f\"\\nDeciles: {deciles}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Axis-based Operations\n",
                "\n",
                "Apply statistical functions along specific axes in multi-dimensional arrays."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create 2D array (students x subjects)\n",
                "# Rows: Students, Columns: Math, Science, English\n",
                "grades = np.array([\n",
                "    [85, 90, 78],  # Student 1\n",
                "    [92, 88, 95],  # Student 2\n",
                "    [78, 85, 82],  # Student 3\n",
                "    [95, 92, 88],  # Student 4\n",
                "    [88, 86, 90]   # Student 5\n",
                "])\n",
                "\n",
                "print(\"Grades (Students x Subjects):\\n\", grades)\n",
                "print(\"Shape:\", grades.shape)\n",
                "\n",
                "print(\"\\n--- Overall Statistics ---\")\n",
                "print(f\"Overall mean: {np.mean(grades):.2f}\")\n",
                "print(f\"Overall std: {np.std(grades):.2f}\")\n",
                "\n",
                "print(\"\\n--- Statistics per Subject (axis=0, down columns) ---\")\n",
                "print(f\"Subject means: {np.mean(grades, axis=0)}\")\n",
                "print(f\"Subject std: {np.std(grades, axis=0)}\")\n",
                "print(f\"Subject max: {np.max(grades, axis=0)}\")\n",
                "print(f\"Subject min: {np.min(grades, axis=0)}\")\n",
                "\n",
                "print(\"\\n--- Statistics per Student (axis=1, across rows) ---\")\n",
                "print(f\"Student means: {np.mean(grades, axis=1)}\")\n",
                "print(f\"Student std: {np.std(grades, axis=1)}\")\n",
                "print(f\"Student max: {np.max(grades, axis=1)}\")\n",
                "print(f\"Student min: {np.min(grades, axis=1)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3D example: Multiple classes\n",
                "# Shape: (classes, students, subjects)\n",
                "all_grades = np.random.randint(70, 100, size=(3, 5, 3))\n",
                "\n",
                "print(\"Shape (classes, students, subjects):\", all_grades.shape)\n",
                "print(\"\\nClass 1 grades:\\n\", all_grades[0])\n",
                "\n",
                "print(\"\\n--- Statistics across different axes ---\")\n",
                "print(f\"Mean per class: {np.mean(all_grades, axis=(1, 2))}\")\n",
                "print(f\"Mean per subject (all classes): {np.mean(all_grades, axis=(0, 1))}\")\n",
                "print(f\"Mean per student (all subjects, all classes): {np.mean(all_grades, axis=2)[0]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Correlation and Covariance\n",
                "\n",
                "Measure relationships between variables."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create correlated data\n",
                "np.random.seed(42)\n",
                "study_hours = np.random.randint(1, 10, size=20)\n",
                "test_scores = study_hours * 8 + np.random.randint(-5, 5, size=20)\n",
                "\n",
                "print(\"Study Hours:\", study_hours)\n",
                "print(\"Test Scores:\", test_scores)\n",
                "\n",
                "# Correlation coefficient\n",
                "correlation = np.corrcoef(study_hours, test_scores)\n",
                "print(\"\\nCorrelation Matrix:\\n\", correlation)\n",
                "print(f\"\\nCorrelation coefficient: {correlation[0, 1]:.3f}\")\n",
                "\n",
                "# Covariance\n",
                "covariance = np.cov(study_hours, test_scores)\n",
                "print(\"\\nCovariance Matrix:\\n\", covariance)\n",
                "print(f\"Covariance: {covariance[0, 1]:.3f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Multiple variables correlation\n",
                "# Variables: Height, Weight, Age\n",
                "height = np.array([165, 170, 180, 175, 160, 185, 172, 168])\n",
                "weight = np.array([60, 70, 85, 75, 55, 90, 72, 65])\n",
                "age = np.array([25, 30, 35, 28, 22, 40, 32, 27])\n",
                "\n",
                "# Stack variables\n",
                "data = np.vstack([height, weight, age])\n",
                "print(\"Data shape:\", data.shape)\n",
                "\n",
                "# Correlation matrix\n",
                "corr_matrix = np.corrcoef(data)\n",
                "print(\"\\nCorrelation Matrix:\")\n",
                "print(\"         Height  Weight  Age\")\n",
                "print(f\"Height   {corr_matrix[0, 0]:.3f}  {corr_matrix[0, 1]:.3f}  {corr_matrix[0, 2]:.3f}\")\n",
                "print(f\"Weight   {corr_matrix[1, 0]:.3f}  {corr_matrix[1, 1]:.3f}  {corr_matrix[1, 2]:.3f}\")\n",
                "print(f\"Age      {corr_matrix[2, 0]:.3f}  {corr_matrix[2, 1]:.3f}  {corr_matrix[2, 2]:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Sorting and Ordering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Basic sorting\n",
                "arr = np.array([64, 34, 25, 12, 22, 11, 90])\n",
                "print(\"Original:\", arr)\n",
                "print(\"Sorted:\", np.sort(arr))\n",
                "print(\"Sorted (descending):\", np.sort(arr)[::-1])\n",
                "\n",
                "# Get indices that would sort the array\n",
                "indices = np.argsort(arr)\n",
                "print(\"\\nSort indices:\", indices)\n",
                "print(\"Sorted using indices:\", arr[indices])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sorting 2D arrays\n",
                "arr_2d = np.array([[3, 2, 1],\n",
                "                   [6, 5, 4],\n",
                "                   [9, 8, 7]])\n",
                "\n",
                "print(\"Original:\\n\", arr_2d)\n",
                "print(\"\\nSort each row:\", np.sort(arr_2d, axis=1))\n",
                "print(\"\\nSort each column:\\n\", np.sort(arr_2d, axis=0))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Partition - find k smallest/largest elements\n",
                "arr = np.array([64, 34, 25, 12, 22, 11, 90, 88, 45, 50])\n",
                "print(\"Array:\", arr)\n",
                "\n",
                "# Find 3 smallest elements\n",
                "k = 3\n",
                "partitioned = np.partition(arr, k)\n",
                "print(f\"\\nPartitioned at {k}:\", partitioned)\n",
                "print(f\"3 smallest: {partitioned[:k]}\")\n",
                "\n",
                "# Find 3 largest elements\n",
                "partitioned = np.partition(arr, -k)\n",
                "print(f\"3 largest: {partitioned[-k:]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Unique Values and Counts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find unique values\n",
                "arr = np.array([1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5])\n",
                "print(\"Array:\", arr)\n",
                "\n",
                "unique_values = np.unique(arr)\n",
                "print(\"\\nUnique values:\", unique_values)\n",
                "\n",
                "# Get counts\n",
                "unique, counts = np.unique(arr, return_counts=True)\n",
                "print(\"\\nValue\\tCount\")\n",
                "for val, count in zip(unique, counts):\n",
                "    print(f\"{val}\\t{count}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bincount - count occurrences of non-negative integers\n",
                "arr = np.array([0, 1, 1, 2, 2, 2, 3, 3, 3, 3])\n",
                "counts = np.bincount(arr)\n",
                "print(\"Array:\", arr)\n",
                "print(\"Counts:\", counts)\n",
                "print(\"\\nIndex\\tCount\")\n",
                "for i, count in enumerate(counts):\n",
                "    print(f\"{i}\\t{count}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Histogram and Binning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create histogram\n",
                "data = np.random.normal(100, 15, 1000)\n",
                "\n",
                "# Create 10 bins\n",
                "hist, bin_edges = np.histogram(data, bins=10)\n",
                "\n",
                "print(\"Histogram:\")\n",
                "print(\"Bin Range\\t\\tCount\")\n",
                "for i in range(len(hist)):\n",
                "    print(f\"[{bin_edges[i]:.1f}, {bin_edges[i+1]:.1f})\\t{hist[i]}\")\n",
                "\n",
                "print(f\"\\nTotal count: {hist.sum()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Digitize - assign values to bins\n",
                "data = np.array([1.2, 2.5, 3.7, 4.1, 5.8, 6.3, 7.9, 8.2])\n",
                "bins = np.array([0, 3, 6, 9])  # Bins: [0-3), [3-6), [6-9)\n",
                "\n",
                "bin_indices = np.digitize(data, bins)\n",
                "print(\"Data:\", data)\n",
                "print(\"Bins:\", bins)\n",
                "print(\"Bin indices:\", bin_indices)\n",
                "\n",
                "# Show which bin each value belongs to\n",
                "for val, bin_idx in zip(data, bin_indices):\n",
                "    if bin_idx < len(bins):\n",
                "        print(f\"{val:.1f} -> Bin {bin_idx} [{bins[bin_idx-1]}, {bins[bin_idx]})\")\n",
                "    else:\n",
                "        print(f\"{val:.1f} -> Bin {bin_idx} [>= {bins[-1]})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Weighted Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Weighted average\n",
                "values = np.array([85, 90, 78, 92])\n",
                "weights = np.array([0.2, 0.3, 0.25, 0.25])  # Must sum to 1\n",
                "\n",
                "print(\"Values:\", values)\n",
                "print(\"Weights:\", weights)\n",
                "\n",
                "weighted_avg = np.average(values, weights=weights)\n",
                "print(f\"\\nWeighted average: {weighted_avg:.2f}\")\n",
                "\n",
                "# Compare with regular average\n",
                "regular_avg = np.mean(values)\n",
                "print(f\"Regular average: {regular_avg:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Practical Examples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example 1: Sales Analysis\n",
                "np.random.seed(42)\n",
                "daily_sales = np.random.normal(1000, 200, 30)  # 30 days of sales\n",
                "\n",
                "print(\"Daily Sales (first 10 days):\", daily_sales[:10].astype(int))\n",
                "print(\"\\n--- Sales Statistics ---\")\n",
                "print(f\"Mean daily sales: ${np.mean(daily_sales):.2f}\")\n",
                "print(f\"Median daily sales: ${np.median(daily_sales):.2f}\")\n",
                "print(f\"Std deviation: ${np.std(daily_sales):.2f}\")\n",
                "print(f\"Best day: ${np.max(daily_sales):.2f}\")\n",
                "print(f\"Worst day: ${np.min(daily_sales):.2f}\")\n",
                "print(f\"Total monthly sales: ${np.sum(daily_sales):.2f}\")\n",
                "\n",
                "# Identify outliers (> 2 std from mean)\n",
                "mean = np.mean(daily_sales)\n",
                "std = np.std(daily_sales)\n",
                "outliers = daily_sales[(daily_sales > mean + 2*std) | (daily_sales < mean - 2*std)]\n",
                "print(f\"\\nOutlier days: {len(outliers)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example 2: Student Performance Analysis\n",
                "# Subjects: Math, Science, English, History, Art\n",
                "student_scores = np.array([\n",
                "    [85, 90, 78, 88, 92],  # Student 1\n",
                "    [92, 88, 95, 85, 90],  # Student 2\n",
                "    [78, 85, 82, 90, 88],  # Student 3\n",
                "    [95, 92, 88, 92, 85],  # Student 4\n",
                "    [88, 86, 90, 87, 91],  # Student 5\n",
                "])\n",
                "\n",
                "subjects = ['Math', 'Science', 'English', 'History', 'Art']\n",
                "\n",
                "print(\"--- Subject Performance ---\")\n",
                "for i, subject in enumerate(subjects):\n",
                "    scores = student_scores[:, i]\n",
                "    print(f\"\\n{subject}:\")\n",
                "    print(f\"  Mean: {np.mean(scores):.1f}\")\n",
                "    print(f\"  Median: {np.median(scores):.1f}\")\n",
                "    print(f\"  Std: {np.std(scores):.1f}\")\n",
                "    print(f\"  Range: {np.min(scores)} - {np.max(scores)}\")\n",
                "\n",
                "print(\"\\n--- Student Performance ---\")\n",
                "for i in range(len(student_scores)):\n",
                "    avg = np.mean(student_scores[i])\n",
                "    print(f\"Student {i+1} average: {avg:.1f}\")\n",
                "\n",
                "# Find best performing subject overall\n",
                "subject_means = np.mean(student_scores, axis=0)\n",
                "best_subject_idx = np.argmax(subject_means)\n",
                "print(f\"\\nBest performing subject: {subjects[best_subject_idx]} ({subject_means[best_subject_idx]:.1f})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example 3: Z-score Normalization\n",
                "data = np.random.normal(100, 15, 100)\n",
                "\n",
                "print(\"Original data (first 10):\", data[:10])\n",
                "print(f\"Mean: {np.mean(data):.2f}, Std: {np.std(data):.2f}\")\n",
                "\n",
                "# Calculate z-scores\n",
                "z_scores = (data - np.mean(data)) / np.std(data)\n",
                "\n",
                "print(\"\\nZ-scores (first 10):\", z_scores[:10])\n",
                "print(f\"Z-score mean: {np.mean(z_scores):.10f}\")  # Should be ~0\n",
                "print(f\"Z-score std: {np.std(z_scores):.10f}\")    # Should be ~1\n",
                "\n",
                "# Find extreme values (|z| > 2)\n",
                "extreme = np.abs(z_scores) > 2\n",
                "print(f\"\\nExtreme values (|z| > 2): {np.sum(extreme)} out of {len(data)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéØ Key Takeaways\n",
                "\n",
                "1. **Descriptive statistics**: mean, median, std, var, min, max\n",
                "2. **Percentiles**: Use `np.percentile()` or `np.quantile()` to understand distribution\n",
                "3. **Axis parameter**: Control which dimension to aggregate (axis=0 for columns, axis=1 for rows)\n",
                "4. **Correlation**: Measure relationships with `np.corrcoef()` and `np.cov()`\n",
                "5. **Sorting**: Use `np.sort()` and `np.argsort()` for ordering data\n",
                "6. **Unique values**: `np.unique()` with `return_counts=True` for frequency analysis\n",
                "7. **Histograms**: `np.histogram()` for data distribution\n",
                "\n",
                "## üìù Practice Exercises\n",
                "\n",
                "1. Calculate the 5-number summary (min, Q1, median, Q3, max) for a dataset\n",
                "2. Identify and remove outliers using the IQR method\n",
                "3. Normalize a dataset using min-max scaling (0 to 1)\n",
                "4. Calculate moving averages for time series data\n",
                "5. Find the most correlated pair of variables in a multi-variable dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your practice code here\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}