{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8734979c",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wasim/Data-Science/blob/main/data-analyst-roadmap/10_machine_learning_basics/03_logistic_regression.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Classify data into categories.\n",
    "\n",
    "## What is Logistic Regression?\n",
    "- Binary classification (Yes/No)\n",
    "- Predicts probabilities (0-1)\n",
    "- Uses sigmoid function\n",
    "- Foundation for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load breast cancer dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(\n",
    "    data.data, \n",
    "    columns=data.feature_names\n",
    ")\n",
    "df['target'] = data.target\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "print(f\"\\n0 = Malignant, 1 = Benign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key features\n",
    "features = [\n",
    "    'mean radius',\n",
    "    'mean texture',\n",
    "    'mean perimeter',\n",
    "    'mean area'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    for target in [0, 1]:\n",
    "        axes[idx].hist(\n",
    "            df[df['target']==target][feature],\n",
    "            alpha=0.6,\n",
    "            label=f\"Class {target}\",\n",
    "            bins=20\n",
    "        )\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)}\")\n",
    "print(f\"Test set: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model trained!\")\n",
    "print(f\"\\nCoefficients:\")\n",
    "for feature, coef in zip(features, model.coef_[0]):\n",
    "    print(f\"{feature}: {coef:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Show sample predictions\n",
    "results = pd.DataFrame({\n",
    "    'Actual': y_test[:10].values,\n",
    "    'Predicted': y_pred[:10],\n",
    "    'Prob_Malignant': y_pred_proba[:10, 0],\n",
    "    'Prob_Benign': y_pred_proba[:10, 1]\n",
    "})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"\\nCorrect: {(y_pred == y_test).sum()}\")\n",
    "print(f\"Incorrect: {(y_pred != y_test).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=['Malignant', 'Benign'],\n",
    "    yticklabels=['Malignant', 'Benign']\n",
    ")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"True Negatives: {cm[0,0]}\")\n",
    "print(f\"False Positives: {cm[0,1]}\")\n",
    "print(f\"False Negatives: {cm[1,0]}\")\n",
    "print(f\"True Positives: {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    y_pred,\n",
    "    target_names=['Malignant', 'Benign']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(\n",
    "    y_test, \n",
    "    y_pred_proba[:, 1]\n",
    ")\n",
    "auc = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(\n",
    "    fpr, tpr, \n",
    "    linewidth=2, \n",
    "    label=f'ROC (AUC = {auc:.3f})'\n",
    ")\n",
    "plt.plot(\n",
    "    [0, 1], [0, 1], \n",
    "    'k--', \n",
    "    label='Random Classifier'\n",
    ")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Score: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different thresholds\n",
    "thresholds_to_test = [0.3, 0.5, 0.7]\n",
    "\n",
    "for threshold in thresholds_to_test:\n",
    "    y_pred_custom = (\n",
    "        y_pred_proba[:, 1] >= threshold\n",
    "    ).astype(int)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred_custom)\n",
    "    \n",
    "    print(f\"\\nThreshold: {threshold}\")\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(classification_report(\n",
    "        y_test, \n",
    "        y_pred_custom,\n",
    "        target_names=['Malignant', 'Benign'],\n",
    "        zero_division=0\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Coefficient': model.coef_[0]\n",
    "}).sort_values('Coefficient', \n",
    "               key=abs, \n",
    "               ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance['Feature'], \n",
    "         importance['Coefficient'])\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New patient data\n",
    "new_patient = pd.DataFrame({\n",
    "    'mean radius': [15.0],\n",
    "    'mean texture': [20.0],\n",
    "    'mean perimeter': [95.0],\n",
    "    'mean area': [700.0]\n",
    "})\n",
    "\n",
    "# Scale and predict\n",
    "new_patient_scaled = scaler.transform(new_patient)\n",
    "prediction = model.predict(new_patient_scaled)\n",
    "probability = model.predict_proba(\n",
    "    new_patient_scaled\n",
    ")\n",
    "\n",
    "print(f\"Prediction: {prediction[0]}\")\n",
    "print(f\"Class: {'Benign' if prediction[0]==1 else 'Malignant'}\")\n",
    "print(f\"\\nProbabilities:\")\n",
    "print(f\"Malignant: {probability[0][0]:.3f}\")\n",
    "print(f\"Benign: {probability[0][1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Build a model to predict customer churn \n",
    "(stayed vs left)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Find the optimal threshold for your \n",
    "use case (minimize false negatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "✅ **Logistic Regression** - Binary classification  \n",
    "✅ **Probabilities** - 0 to 1 predictions  \n",
    "✅ **Confusion Matrix** - Understand errors  \n",
    "✅ **ROC/AUC** - Model performance  \n",
    "✅ **Threshold** - Tune for use case  \n",
    "\n",
    "**Next:** [Model Evaluation](04_model_evaluation.ipynb) →"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
